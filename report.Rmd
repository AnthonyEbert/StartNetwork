---
title: "Report"
author: "Anthony Ebert"
date: "22/08/2019"
output: pdf_document
bibliography: link.bib
---

$$
\begin{aligned}
KL[q(\cdot)||p(\cdot|\theta)] &= \sum_{y \in \mathcal{Y}} q(y) \log \frac{ q(y) }{p(y|\theta)} \\
&= \log[z(\theta)] - \sum_{y \in \mathcal{Y}} q(y) \left[ \sum_i \theta_i s_i(y) \right] + \sum_{y \in \mathcal{Y}} q(y) \log q(y) 
\end{aligned}
$$

# Entropy estimation

I use the following non-parameteric estimator of entropy [@vu2007coverage]:

$$
\begin{aligned}
\tilde{H} &:= - \sum_k \frac{\tilde{p}_k \log \tilde{p}_k}{1 - (1-\tilde{p}_k)^n} \\
\tilde{p}_k &:= \hat{C}\hat{p}_k \\
\hat{C} &:= 1 - \frac{\#\{k|n_k = 1\}}{\sum_k n_k}\\
\hat{p}_k &:= \frac{n_k}{n}
\end{aligned}
$$

For instance

```{r}
library(StartNetwork)

x <- rbinom(1000, 10, 0.1)
head(x)

mean(-log(dbinom(x, size = 10, 0.1)))
entropy_calc(x)

x <- rbinom(1000, 10, 0.2)
head(x)

mean(-log(dbinom(x, size = 10, 0.2)))
entropy_calc(x)

```

# The relative importance of the likelihood and entropy

```{r, fig.cap="KL divergence calculation with entropy"}
library(ggplot2)

x <- sapply(seq(0.025, 0.975, by = 0.025), er_KL, pl = 0.3, include_entropy = TRUE)


ggplot2::qplot(seq(0.025, 0.975, by = 0.025),x, xlab = "dyad connection probability", ylab = "KL divergence") + ggplot2::geom_vline(aes(xintercept = x), data = data.frame(x = 0.3), col = "red")


```

```{r, fig.cap = "KL divergence calculation without entropy"}
y <- sapply(seq(0.025, 0.975, by = 0.025), er_KL, pl = 0.3, include_entropy = FALSE)
ggplot2::qplot(seq(0.025, 0.975, by = 0.025),y, xlab = "dyad connection probability", ylab = "KL divergence") + ggplot2::geom_vline(aes(xintercept = x), data = data.frame(x = 0.3), col = "red")
```


```{r, fig.cap="KL divergence calculation with entropy"}

x <- sapply(seq(0.275, 0.325, by = 0.005), er_KL, pl = 0.3, include_entropy = TRUE, replicates = 5000)

ggplot2::qplot(seq(0.275, 0.325, by = 0.005),x, xlab = "dyad connection probability", ylab = "KL divergence") + ggplot2::geom_vline(aes(xintercept = x), data = data.frame(x = 0.3), col = "red")
```


```{r, fig.cap="KL divergence calculation without entropy"}
x <- sapply(seq(0.275, 0.325, by = 0.005), er_KL, pl = 0.3, include_entropy = FALSE, replicates = 5000)

ggplot2::qplot(seq(0.275, 0.325, by = 0.005),x, xlab = "dyad connection probability", ylab = "KL divergence") + ggplot2::geom_vline(aes(xintercept = x), data = data.frame(x = 0.3), col = "red")

```


# Attempt with preferential attachment model

The preferential attachment model has the following likelihood function:

$$
\begin{aligned}
P(k | \rho) &= \frac{(\rho - 1) \Gamma(k) \Gamma(\rho)}{\Gamma(k + \rho)}
\end{aligned}
$$

In this case there is no simple set of summary statistics. 

```{r}

x <- sapply(seq(2.5, 5.5, by = 0.1), ba_KL, pl = 4.5)

ggplot2::qplot(seq(2.5, 5.5, by = 0.1),x, xlab = "power parameter", ylab = "KL divergence") + ggplot2::geom_vline(aes(xintercept = x), data = data.frame(x = 4.5), col = "red")
```








